{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='VMKOO8KZ8D9ptA', \\\n",
    "                     client_secret='wuVtgi5hMc_mt5af37DpCUeubtQ', \\\n",
    "                     user_agent='Censorship analysis', \\\n",
    "                     username='stannida')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Subreddits.csv', names=['links'])\n",
    "df['subreddits'] = df['links'].apply(lambda x: x.split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)\n",
    "\n",
    "def get_reddit_data(reddit, reddit_branch):\n",
    "    \n",
    "    subreddit = reddit.subreddit(reddit_branch)\n",
    "    top_subreddit = subreddit.top(limit=1000)\n",
    "    \n",
    "    topics_dict = { \"title\":[], \n",
    "                    \"score\":[], \n",
    "                    \"id\":[], \"url\":[], \n",
    "                    \"comms_num\": [], \n",
    "                    \"created\": [], \n",
    "                    \"body\":[],\n",
    "                    \"comments\":[]}\n",
    "    \n",
    "    for submission in top_subreddit:\n",
    "        topics_dict[\"title\"].append(submission.title)\n",
    "        topics_dict[\"score\"].append(submission.score)\n",
    "        topics_dict[\"id\"].append(submission.id)\n",
    "        topics_dict[\"url\"].append(submission.url)\n",
    "        topics_dict[\"comms_num\"].append(submission.num_comments)\n",
    "        topics_dict[\"created\"].append(submission.created)\n",
    "        topics_dict[\"body\"].append(submission.selftext)\n",
    "        submission.comments.replace_more(limit=0)\n",
    "        comments = []\n",
    "        for top_level_comment in submission.comments:\n",
    "            comments.append(top_level_comment.body)\n",
    "        topics_dict[\"comments\"].append(comments)\n",
    "        \n",
    "    topics_data = pd.DataFrame(topics_dict)\n",
    "    _timestamp = topics_data[\"created\"].apply(get_date)\n",
    "    topics_data = topics_data.assign(timestamp = _timestamp)\n",
    "    topics_data.to_csv('reddit_' + reddit_branch + '.csv', index=False) \n",
    "    print('Data saved to reddit_' + reddit_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reddit_branch in df['subreddits']:\n",
    "    get_reddit_data(reddit, reddit_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
